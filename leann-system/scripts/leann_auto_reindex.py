#!/usr/bin/env python3
"""
LEANN Auto-Reindexa√ß√£o Baseada em Mudan√ßas
Monitora modifica√ß√µes no MyVault e reindex automaticamente quando necess√°rio
"""

import os
import sys
import time
import hashlib
import subprocess
import json
from datetime import datetime, timedelta
from pathlib import Path
import logging

# Configura√ß√µes
VAULT_PATH = "/var/lib/docker/volumes/docker-compose_obsidian-vaults/_data/MyVault"
INDEX_NAME = "myvault"
METADATA_FILE = "/tmp/leann_reindex_metadata.json"
LOG_FILE = "/var/log/leann-reindex.log"
CHECK_INTERVAL = 300  # 5 minutos
MIN_REINDEX_INTERVAL = 3600  # 1 hora m√≠nima entre reindexa√ß√µes

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

def calculate_vault_hash():
    """Calcula hash MD5 de todos os arquivos .md no vault"""
    hash_md5 = hashlib.md5()
    
    md_files = []
    for root, dirs, files in os.walk(VAULT_PATH):
        # Ignorar diret√≥rios ocultos
        dirs[:] = [d for d in dirs if not d.startswith('.')]
        
        for file in sorted(files):
            if file.endswith('.md'):
                file_path = os.path.join(root, file)
                try:
                    # Adicionar path relativo e timestamp
                    rel_path = os.path.relpath(file_path, VAULT_PATH)
                    mtime = os.path.getmtime(file_path)
                    size = os.path.getsize(file_path)
                    
                    # Hash do conte√∫do do arquivo
                    with open(file_path, 'rb') as f:
                        file_content = f.read()
                        file_hash = hashlib.md5(file_content).hexdigest()
                    
                    # Combinar informa√ß√µes do arquivo
                    file_info = f"{rel_path}:{mtime}:{size}:{file_hash}"
                    hash_md5.update(file_info.encode())
                    md_files.append({
                        'path': rel_path,
                        'mtime': mtime,
                        'size': size,
                        'hash': file_hash
                    })
                    
                except Exception as e:
                    logger.warning(f"Erro ao processar {file_path}: {e}")
                    continue
    
    return hash_md5.hexdigest(), md_files

def load_metadata():
    """Carrega metadata da √∫ltima verifica√ß√£o"""
    try:
        if os.path.exists(METADATA_FILE):
            with open(METADATA_FILE, 'r') as f:
                return json.load(f)
    except Exception as e:
        logger.warning(f"Erro ao carregar metadata: {e}")
    
    return {
        'last_hash': None,
        'last_reindex': 0,
        'last_check': 0,
        'total_files': 0,
        'reindex_count': 0
    }

def save_metadata(metadata):
    """Salva metadata da verifica√ß√£o atual"""
    try:
        with open(METADATA_FILE, 'w') as f:
            json.dump(metadata, f, indent=2)
    except Exception as e:
        logger.error(f"Erro ao salvar metadata: {e}")

def needs_reindex(current_hash, metadata):
    """Verifica se reindexa√ß√£o √© necess√°ria"""
    # Mudan√ßa no conte√∫do
    if current_hash != metadata.get('last_hash'):
        return True, "Conte√∫do modificado"
    
    # Reindexa√ß√£o for√ßada a cada 24h (backup)
    last_reindex = metadata.get('last_reindex', 0)
    if time.time() - last_reindex > 86400:  # 24 horas
        return True, "Reindexa√ß√£o di√°ria de seguran√ßa"
    
    return False, "Nenhuma mudan√ßa detectada"

def run_leann_reindex():
    """Executa reindexa√ß√£o do LEANN"""
    try:
        logger.info("üîÑ Iniciando reindexa√ß√£o LEANN...")
        
        cmd = [
            "leann", "build", INDEX_NAME,
            "--docs", VAULT_PATH,
            "--file-types", ".md",
            "--embedding-mode", "openai",
            "--embedding-model", "text-embedding-3-small",
            "--force"
        ]
        
        # Executar comando
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            cwd="/root",
            env={**os.environ, 
                 "PATH": "/root/.local/bin:" + os.environ.get("PATH", ""),
                 "OPENAI_API_KEY": os.environ.get("OPENAI_API_KEY", "")}
        )
        
        if result.returncode == 0:
            logger.info("‚úÖ Reindexa√ß√£o LEANN conclu√≠da com sucesso")
            return True
        else:
            logger.error(f"‚ùå Erro na reindexa√ß√£o: {result.stderr}")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Erro ao executar reindexa√ß√£o: {e}")
        return False

def clear_redis_cache():
    """Limpa cache Redis ap√≥s reindexa√ß√£o"""
    try:
        import redis
        r = redis.Redis(host='localhost', port=26379, db=1, decode_responses=True)
        
        # Buscar chaves do cache LEANN
        leann_keys = r.keys("leann:*")
        if leann_keys:
            deleted = r.delete(*leann_keys)
            logger.info(f"üóëÔ∏è Cache Redis limpo: {deleted} chaves removidas")
        else:
            logger.info("üóëÔ∏è Cache Redis j√° vazio")
            
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Erro ao limpar cache Redis: {e}")

def monitor_vault():
    """Loop principal de monitoramento"""
    logger.info("üöÄ Iniciando monitoramento LEANN auto-reindex")
    logger.info(f"üìÅ Monitorando: {VAULT_PATH}")
    logger.info(f"‚è∞ Intervalo de verifica√ß√£o: {CHECK_INTERVAL}s")
    
    while True:
        try:
            # Carregar metadata
            metadata = load_metadata()
            
            # Calcular hash atual
            current_hash, file_list = calculate_vault_hash()
            total_files = len(file_list)
            
            logger.info(f"üìä Verifica√ß√£o: {total_files} arquivos .md encontrados")
            
            # Verificar se precisa reindexar
            should_reindex, reason = needs_reindex(current_hash, metadata)
            
            if should_reindex:
                # Verificar intervalo m√≠nimo
                last_reindex = metadata.get('last_reindex', 0)
                time_since_last = time.time() - last_reindex
                
                if time_since_last < MIN_REINDEX_INTERVAL:
                    wait_time = MIN_REINDEX_INTERVAL - time_since_last
                    logger.info(f"‚è≥ Aguardando intervalo m√≠nimo: {wait_time/60:.1f} min")
                else:
                    logger.info(f"üîÑ Reindexa√ß√£o necess√°ria: {reason}")
                    
                    # Executar reindexa√ß√£o
                    if run_leann_reindex():
                        # Limpar cache Redis
                        clear_redis_cache()
                        
                        # Atualizar metadata
                        metadata.update({
                            'last_hash': current_hash,
                            'last_reindex': time.time(),
                            'last_check': time.time(),
                            'total_files': total_files,
                            'reindex_count': metadata.get('reindex_count', 0) + 1
                        })
                        
                        logger.info(f"‚úÖ Reindexa√ß√£o #{metadata['reindex_count']} conclu√≠da")
                    else:
                        logger.error("‚ùå Falha na reindexa√ß√£o")
            else:
                logger.info(f"‚úÖ {reason}")
                
                # Atualizar apenas timestamp da verifica√ß√£o
                metadata.update({
                    'last_check': time.time(),
                    'total_files': total_files
                })
            
            # Salvar metadata
            save_metadata(metadata)
            
            # Aguardar pr√≥xima verifica√ß√£o
            logger.info(f"üò¥ Pr√≥xima verifica√ß√£o em {CHECK_INTERVAL/60:.1f} min")
            time.sleep(CHECK_INTERVAL)
            
        except KeyboardInterrupt:
            logger.info("üõë Monitoramento interrompido pelo usu√°rio")
            break
        except Exception as e:
            logger.error(f"‚ùå Erro no loop principal: {e}")
            time.sleep(60)  # Aguardar 1 min antes de tentar novamente

def show_status():
    """Mostra status atual do monitoramento"""
    metadata = load_metadata()
    
    print("üìä LEANN Auto-Reindex Status")
    print("=" * 40)
    
    if metadata.get('last_check'):
        last_check = datetime.fromtimestamp(metadata['last_check'])
        print(f"üïê √öltima verifica√ß√£o: {last_check.strftime('%Y-%m-%d %H:%M:%S')}")
    
    if metadata.get('last_reindex'):
        last_reindex = datetime.fromtimestamp(metadata['last_reindex'])
        print(f"üîÑ √öltima reindexa√ß√£o: {last_reindex.strftime('%Y-%m-%d %H:%M:%S')}")
    
    print(f"üìÅ Total de arquivos: {metadata.get('total_files', 'N/A')}")
    print(f"üî¢ Reindexa√ß√µes realizadas: {metadata.get('reindex_count', 0)}")
    
    if metadata.get('last_hash'):
        print(f"üîê Hash atual: {metadata['last_hash'][:16]}...")

if __name__ == "__main__":
    if len(sys.argv) > 1:
        if sys.argv[1] == "status":
            show_status()
        elif sys.argv[1] == "force":
            logger.info("üîÑ For√ßando reindexa√ß√£o...")
            if run_leann_reindex():
                clear_redis_cache()
                logger.info("‚úÖ Reindexa√ß√£o for√ßada conclu√≠da")
            else:
                logger.error("‚ùå Falha na reindexa√ß√£o for√ßada")
        else:
            print("Uso: python3 leann_auto_reindex.py [status|force]")
    else:
        monitor_vault()